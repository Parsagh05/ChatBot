{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4d7e0a0",
    "outputId": "ebec419f-b6ac-4793-91c7-8ff8f17370c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\program files\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\program files\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.11.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\program files\\anaconda3\\lib\\site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in d:\\program files\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\program files\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in d:\\program files\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\program files\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in d:\\program files\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "   ---------------------------------------- 0.0/948.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 30.7/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   - ------------------------------------- 41.0/948.6 kB 960.0 kB/s eta 0:00:01\n",
      "   -- ------------------------------------ 71.7/948.6 kB 491.5 kB/s eta 0:00:02\n",
      "   ------ ------------------------------- 153.6/948.6 kB 833.5 kB/s eta 0:00:01\n",
      "   ------- ------------------------------ 194.6/948.6 kB 841.6 kB/s eta 0:00:01\n",
      "   --------- ---------------------------- 235.5/948.6 kB 901.1 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 307.2/948.6 kB 999.9 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 337.9/948.6 kB 952.6 kB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 409.6/948.6 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 491.5/948.6 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 573.4/948.6 kB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 655.4/948.6 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 737.3/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 819.2/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 901.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  942.1/948.6 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- 948.6/948.6 kB 706.1 kB/s eta 0:00:00\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "   ---------------------------------------- 0.0/253.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 61.4/253.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 143.4/253.0 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 204.8/253.0 kB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 245.8/253.0 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 245.8/253.0 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 245.8/253.0 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- 253.0/253.0 kB 863.9 kB/s eta 0:00:00\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.11.0-cp311-cp311-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/204.3 kB ? eta -:--:--\n",
      "   ----------- --------------------------- 61.4/204.3 kB 812.7 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 102.4/204.3 kB 837.8 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 102.4/204.3 kB 837.8 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 143.4/204.3 kB 652.5 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 194.6/204.3 kB 784.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- 204.3/204.3 kB 326.7 kB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 10.2/44.6 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 41.0/44.6 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.6 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.6 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.6 kB 653.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.6 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.6/44.6 kB 115.7 kB/s eta 0:00:00\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, jiter, h11, python-docx, httpcore, httpx, openai\n",
      "Successfully installed h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.11.0 openai-1.109.1 python-docx-1.2.0 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'C:\\Users\\USER\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jpHWiO3P8ts9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    \"\"\"\n",
    "    A class to encapsulate the RAG chatbot functionality,\n",
    "    allowing for custom API endpoints.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key, model=\"gpt-4.1-mini\", base_url=\"https://api.metisai.ir/openai/v1\"):\n",
    "        \"\"\"\n",
    "        Initializes the Chatbot, setting up the OpenAI client with a custom base URL.\n",
    "        \"\"\"\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OpenAI API key is required.\")\n",
    "        \n",
    "        self.model = model\n",
    "        try:\n",
    "            self.client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing OpenAI client: {e}\")\n",
    "            self.client = None\n",
    "\n",
    "    def load_knowledge_base(self, directory=\"knowledge_docs\"):\n",
    "        \"\"\"\n",
    "        Loads knowledge from all .docx files in a specified directory.\n",
    "        It now chunks the document by blank lines (double newlines) to keep related paragraphs together.\n",
    "        \"\"\"\n",
    "        all_chunks = []\n",
    "        print(f\"Loading knowledge from directory: '{directory}'...\")\n",
    "        if not os.path.exists(directory) or not os.path.isdir(directory):\n",
    "            print(f\"Error: The directory '{directory}' was not found.\")\n",
    "            print(\"Please create it and add your .docx knowledge files.\")\n",
    "            return []\n",
    "        \n",
    "        doc_files = [f for f in os.listdir(directory) if f.endswith(\".docx\")]\n",
    "        if not doc_files:\n",
    "            print(f\"Warning: No .docx files found in the '{directory}' directory.\")\n",
    "            return []\n",
    "\n",
    "        for filename in doc_files:\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                doc = docx.Document(filepath)\n",
    "                # Reconstruct the full text to handle chunks separated by blank lines\n",
    "                full_text = \"\\n\".join(p.text for p in doc.paragraphs)\n",
    "                # Split by double newline (which signifies a blank line in the doc)\n",
    "                chunks = [chunk.strip() for chunk in full_text.split('\\n\\n') if chunk.strip()]\n",
    "                all_chunks.extend(chunks)\n",
    "                print(f\"  - Loaded {len(chunks)} chunks from {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  - Could not read {filename}. Skipping. Error: {e}\")\n",
    "        \n",
    "        print(f\"Total knowledge chunks loaded: {len(all_chunks)}\")\n",
    "        return all_chunks\n",
    "\n",
    "    def print_knowledge_base(self, knowledge_chunks):\n",
    "        \"\"\"Prints the loaded knowledge base chunks for verification.\"\"\"\n",
    "        print(\"\\n--- Knowledge Base Loaded ---\")\n",
    "        if not knowledge_chunks:\n",
    "            print(\"The knowledge base is empty or could not be loaded.\")\n",
    "        else:\n",
    "            for i, chunk in enumerate(knowledge_chunks):\n",
    "                print(f\"  Chunk {i+1}: {chunk[:80]}...\")\n",
    "        print(\"-----------------------------\\n\")\n",
    "\n",
    "    def retrieve_relevant_chunks(self, query, knowledge_chunks):\n",
    "        \"\"\"\n",
    "        Performs 'naive' retrieval by finding the chunk with the most keyword matches.\n",
    "        \"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        best_chunk = \"\"\n",
    "        max_score = 0\n",
    "\n",
    "        if not knowledge_chunks:\n",
    "            return \"No knowledge base loaded.\"\n",
    "\n",
    "        for chunk in knowledge_chunks:\n",
    "            chunk_words = set(chunk.lower().split())\n",
    "            score = len(query_words.intersection(chunk_words))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_chunk = chunk\n",
    "        \n",
    "        if max_score > 0:\n",
    "            return best_chunk\n",
    "        else:\n",
    "            return knowledge_chunks[0]\n",
    "\n",
    "    def generate_response(self, query, context):\n",
    "        \"\"\"\n",
    "        Generates a response using the specified model and context.\n",
    "        \"\"\"\n",
    "        if not self.client:\n",
    "            return \"OpenAI client is not initialized. Cannot generate response.\"\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "        شما یک دستیار خدمات مشتری متخصص و دوستانه برای یک شرکت هستید. نام شما «پشتیبان» است.\n",
    "        شما باید فقط و فقط بر اساس «زمینه» ارائه شده به «سوال» کاربر پاسخ دهید.\n",
    "        اطلاعاتی را از خودتان اضافه نکنید. اگر زمینه برای پاسخ دادن کافی نیست،\n",
    "        مودبانه بگویید که اطلاعات کافی برای پاسخ به آن سوال را ندارید.\n",
    "        ***شما باید همیشه و فقط به زبان فارسی پاسخ دهید.***\n",
    "        \"\"\"\n",
    "        \n",
    "        user_prompt = f\"زمینه: \\\"{context}\\\"\\n\\nسوال: \\\"{query}\\\"\"\n",
    "\n",
    "        try:\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                temperature=0.5,\n",
    "            )\n",
    "            return completion.choices[0].message.content\n",
    "        except openai.APIError as e:\n",
    "            print(f\"OpenAI API Error: {e}\")\n",
    "            return \"متاسفانه در ارتباط با هوش مصنوعی خطایی رخ داد. لطفا دوباره تلاش کنید.\"\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "            return \"یک خطای غیرمنتظره رخ داد. لطفا با پشتیبانی تماس بگیرید.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7zlNT_vT8z6t"
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    \"\"\"Main function to initialize and run the chatbot loop.\"\"\"\n",
    "    print(\"--- ربات چت فارسی با RAG و مدل سفارشی ---\")\n",
    "\n",
    "    api_key = \"tpsg-HURAqpPOuLGZtEReVzj3unfTRXGp45o\"\n",
    "    if not api_key:\n",
    "        print(\"Error: The OPENAI_API_KEY environment variable is not set.\")\n",
    "        print(\"Please set it before running the script.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        chatbot = Chatbot(api_key=api_key)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return\n",
    "\n",
    "    print(\"برای خروج 'خروج' را تایپ کنید\")\n",
    "\n",
    "    knowledge = chatbot.load_knowledge_base(\"C:/Users/USER/Desktop/chatbot-project/knowledge_docs\")\n",
    "\n",
    "    if not knowledge:\n",
    "        return\n",
    "\n",
    "    chatbot.print_knowledge_base(knowledge)\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"شما: \")\n",
    "        if user_query.lower() == 'خروج':\n",
    "            break\n",
    "\n",
    "        context_chunk = chatbot.retrieve_relevant_chunks(user_query, knowledge)\n",
    "        answer = chatbot.generate_response(user_query, context_chunk)\n",
    "\n",
    "        print(f\"جم: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8kS4sQan_BUA"
   },
   "outputs": [],
   "source": [
    "# print_knowledge_base(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Shmn4F9GKcvD",
    "outputId": "0b4dc939-d344-45d6-c372-e13dae4fa827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ربات چت فارسی با RAG و مدل سفارشی ---\n",
      "برای خروج 'خروج' را تایپ کنید\n",
      "Loading knowledge from directory: 'C:/Users/USER/Desktop/knowledge_docs'...\n",
      "  - Loaded 2 chunks from 01- درباره شرکت تابان انرژی- Rev02.docx\n",
      "  - Loaded 15 chunks from 02- معرفی تابان در مجله - Rev05.docx\n",
      "  - Loaded 1 chunks from 03- 07- فروشگاه.docx\n",
      "  - Loaded 19 chunks from 05- سایــر.docx\n",
      "Total knowledge chunks loaded: 37\n",
      "\n",
      "--- Knowledge Base Loaded ---\n",
      "  Chunk 1: شرکت تابان انرژی مازند سو\n",
      "در راستای گسترش انرژی های تجدیدپذیر از جمله انرژی فتوو...\n",
      "  Chunk 2: اهداف شرکت\n",
      "استفاده از انرژی خورشیدی در راستای کاهش آلودگی محیط زیست.\n",
      "تنوع بخشی د...\n",
      "  Chunk 3: در راستای گسترش انرژی های تجدیدپذیر از جمله انرژی فتوولتائیک، بعنوان اولین تولید...\n",
      "  Chunk 4: اهداف شرکت تابان انرژی مازند سو را می توان بطور خلاصه به شرح ذیل ارائه نمود.\n",
      "است...\n",
      "  Chunk 5: همانطور که در شکل نشان داده شده میزان تابش در بدترین نقطه ایران که متعلق به منطق...\n",
      "  Chunk 6: ناترازی برق در زمان اوج مصرف از سال ۱۳۹۶ تا ۱۴۰۳\n",
      "مهم‌ترین عوامل ناترازی برق در س...\n",
      "  Chunk 7: ضرورت توسعه نیروگاه‌های خورشیدی\n",
      "با افزایش مصرف برق در ایران و مواجهه با چالش‌های...\n",
      "  Chunk 8: برنامه ریزی شرکت تابان انـــــرژی مازند سو برای توسعه و احداث نیروگاه های خورشید...\n",
      "  Chunk 9: برای توسعه نیروگاه های خورشیدی با هدف تامین برق و افزایش تولید نیروگاه های خورشی...\n",
      "  Chunk 10: سخن آخـــــر: راهکارکلیدی توسعه نیروگاه‌های خورشیدی در استان مازندران\n",
      "راهکارکلید...\n",
      "  Chunk 11: نمونه پروژه های اجرای نیروگاه خورشیدی در پروژه ها:...\n",
      "  Chunk 12: اجرای نیروگاه 5 کیلوات خورشیدی تزریق به شبکه برق به 12 عدد پنل خورشیدی در 2 ردیف...\n",
      "  Chunk 13: نصب پنل بر روی سقف خانه مسکونی با توجه با سطح صاف در سقف. جهت اجرای پنل به سمت ج...\n",
      "  Chunk 14: اجــرای نیروگاه خورشیدی با قابلیت تزریق به شبکه و مصرف داخلی...\n",
      "  Chunk 15: اجــرای نیروگاه خورشیدی در سقف کارخانه...\n",
      "  Chunk 16: آدرس سایت شرکت تابان انرژی مازند سو:\n",
      "https://tabenergy.ir/...\n",
      "  Chunk 17: با تشکر\n",
      "دکتر احمدعلی غلامی\n",
      "05/02/1404...\n",
      "  Chunk 18: فروشگاه  تابان انرژی مازند سو:   شامل هریک از گزینه های ذیل می باشد \n",
      "باتری خورشی...\n",
      "  Chunk 19: متن برای نیروگاه متصل به شبکه 5 کیلوات...\n",
      "  Chunk 20: پاراگراف اول:\n",
      "این نیروگاه خورشیدی ۶ کیلوواتی با هدف تزریق برق به شبکه سراسری و ب...\n",
      "  Chunk 21: پاراگراف سوم:\n",
      "احداث یک نیروگاه خورشیدی ۵ کیلوواتی نقش قابل‌توجهی در کاهش آلایندگ...\n",
      "  Chunk 22: پاراگراف تکمیلی:\n",
      "یک نیروگاه خورشیدی ۵ کیلوواتی علاوه بر مزایای زیست‌محیطی فوق، م...\n",
      "  Chunk 23: برای کسب اطلاعات بیشتر با واحد فنی شرکت می توان تماس حاصل نمود.\n",
      "کارشناسان شرکت د...\n",
      "  Chunk 24: متن نیروگاه هیبریدی...\n",
      "  Chunk 25: پاراگراف اول:\n",
      "این نیروگاه خورشیدی 20  کیلوواتی هیبریدی با قابلیت تولید همزمان بر...\n",
      "  Chunk 26: برای کسب اطلاعات بیشتر با واحد فنی شرکت می توان تماس حاصل نمود.\n",
      "کارشناسان شرکت د...\n",
      "  Chunk 27: متن نیروگاه منفصل...\n",
      "  Chunk 28: معرفی نیروگاه خورشیدی منفصل و قابلیت‌های آن\n",
      "نیروگاه‌های خورشیدی منفصل از شبکه (O...\n",
      "  Chunk 29: برای کسب اطلاعات بیشتر با واحد فنی شرکت می توان تماس حاصل نمود.\n",
      "کارشناسان شرکت د...\n",
      "  Chunk 30: متن چراغ خورشیدی\n",
      "پاراگراف معرفی روشنایی خورشیدی:...\n",
      "  Chunk 31: سیستم‌های روشنایی خورشیدی، راه‌حلی هوشمند و پایدار برای تأمین نور بدون نیاز به ب...\n",
      "  Chunk 32: برای کسب اطلاعات بیشتر با واحد فنی شرکت می توان تماس حاصل نمود.\n",
      "کارشناسان شرکت د...\n",
      "  Chunk 33: سیستم گرمایش خورشیدی\n",
      "پاراگراف اول:\n",
      "سیستم گرمایش خورشیدی با استفاده از کلکتورهای ...\n",
      "  Chunk 34: برای کسب اطلاعات بیشتر با واحد فنی شرکت می توان تماس حاصل نمود.\n",
      "کارشناسان شرکت د...\n",
      "  Chunk 35: متن آبیاری خورشیدی...\n",
      "  Chunk 36: پاراگراف اول:\n",
      "پمپ آب خورشیدی و سیستم آبیاری خورشیدی، راه‌حلی نوین و پایدار برای ...\n",
      "  Chunk 37: برای کسب اطلاعات بیشتر با واحد فنی شرکت می توان تماس حاصل نمود.\n",
      "کارشناسان شرکت د...\n",
      "-----------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "شما:  اسم مدیریت شرکت چیست؟\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جم: مدیر عامل شرکت تابان انرژی مازند سو دکتر احمدعلی غلامی است.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "شما:  فروشگاه شامل چه محصولاتی است؟\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جم: فروشگاه تابان انرژی مازند سو شامل محصولات زیر می‌باشد:\n",
      "باتری خورشیدی، چراغ خورشیدی، اینورتر هیبریدی، اینورتر متصل به شبکه، اینورتر منفصل از شبکه، پنل خورشیدی و سایر لوازم و تجهیزات مرتبط.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "شما:  برای کسب اطلاعات بیشتر چه کار کنیم؟\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جم: برای کسب اطلاعات بیشتر می‌توانید با واحد فنی شرکت تماس حاصل نمایید. کارشناسان ما در هر زمان آماده ارائه خدمات طراحی، مشاوره و اجرای نیروگاه‌های خورشیدی در سراسر کشور هستند.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "شما:  شاخص های زیست محیطی رو میگی؟\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جم: با توجه به اطلاعات ارائه شده، شرکت تابان انرژی مازند سو با تمرکز بر استفاده از انرژی‌های تجدیدپذیر و پاک، بخصوص انرژی خورشیدی با تکنولوژی نانو وایر، به کاهش آلودگی‌های زیست‌محیطی ناشی از سوخت‌های فسیلی کمک می‌کند. این شرکت با تولید پنل‌های خورشیدی، به کاهش گرمایش زمین و تغییرات نگران‌کننده آب و هوایی کمک می‌نماید. بنابراین، شاخص‌های زیست محیطی مرتبط با فعالیت‌های این شرکت شامل کاهش انتشار گازهای گلخانه‌ای، کاهش آلودگی هوا، استفاده از منابع انرژی پاک و تجدیدپذیر و حمایت از توسعه پایدار می‌باشد. اگر نیاز به اطلاعات دقیق‌تر یا شاخص‌های خاص دارید، لطفاً اعلام بفرمایید.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "شما:  خروج\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
